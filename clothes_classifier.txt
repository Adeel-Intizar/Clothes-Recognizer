# -*- coding: utf-8 -*-
"""Clothes Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJyfHM8DC7FQcLryz6gyeTPamnFQj7Hg
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
from tensorflow import keras
import numpy as np
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import tensorflow as tf

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = train_images / 255.0
test_images = test_images / 255.0

train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)
test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)

y_train = to_categorical(train_labels, 10)
y_test = to_categorical(test_labels, 10)

model = keras.Sequential([
                          keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=keras.regularizers.l2(0.001), input_shape  = (28, 28, 1)),
                          # keras.layers.BatchNormalization(),
                          keras.layers.MaxPooling2D((2,2)),

                          keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=keras.regularizers.l2(0.001)),
                          # keras.layers.BatchNormalization(),
                          keras.layers.MaxPooling2D((2,2)),

                          keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=keras.regularizers.l2(0.001)),
                          # keras.layers.BatchNormalization(),
                          keras.layers.MaxPooling2D((2,2)),

                          keras.layers.Flatten(),
                          keras.layers.Dense(1000, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=keras.regularizers.l2(0.001)),
                          keras.layers.Dense(10, activation='softmax')
])

model.summary()

class myCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs = {}):
    if (logs.get('loss') < 0.01):
      print('Loss is Lower, Cancelling Training')
      self.model.stop_training = True


callback = myCallback()

# OR You Can Use EarlyStopping from tf.keras.callbacks.EarlyStopping

my_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=9, mode='min', restore_best_weights=True)

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])

model.fit(train_images, train_labels, epochs=100, callbacks=[my_callback], validation_split=0.2, batch_size=256)

loss, acc = model.evaluate(train_images, train_labels, verbose=0)
print(f'Training Loss: {loss:.3}, \t Training Accuracy: {acc:.3}' )
loss, acc = model.evaluate(test_images, test_labels, verbose=0)
print(f'Testing Loss: {loss:.3}, \t Testing Accuracy: {acc:.3}')

json = model.to_json()

with open('model.json', 'w') as json_f:
  json_f.write(json)

yaml = model.to_yaml()

with open('model.yaml', 'w') as yaml_f:
  yaml_f.write(yaml)

model.save('Keras_Model.h5')

